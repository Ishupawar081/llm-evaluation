{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sd9pUwpsAWD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from src.metrics import (\n",
        "    tokenize, cosine_similarity, completeness_score,\n",
        "    hallucination_score, estimate_tokens, estimate_cost\n",
        ")\n",
        "\n",
        "def load_file_text(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "def load_json_safe(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read()\n",
        "\n",
        "    # Fix common JSON issues\n",
        "    raw = raw.replace(\",\\n}\", \"\\n}\")\n",
        "    raw = raw.replace(\",\\n]\", \"\\n]\")\n",
        "\n",
        "    try:\n",
        "        return json.loads(raw)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ JSON parsing failed, falling back to text-only mode\")\n",
        "        return None\n",
        "\n",
        "def extract_last_turns_fallback(raw_text):\n",
        "    user_msgs = re.findall(\n",
        "        r'\"role\"\\s*:\\s*\"User\".*?\"message\"\\s*:\\s*\"(.*?)\"',\n",
        "        raw_text,\n",
        "        re.DOTALL\n",
        "    )\n",
        "    ai_msgs = re.findall(\n",
        "        r'\"role\"\\s*:\\s*\"AI/Chatbot\".*?\"message\"\\s*:\\s*\"(.*?)\"',\n",
        "        raw_text,\n",
        "        re.DOTALL\n",
        "    )\n",
        "\n",
        "    user_q = user_msgs[-1] if user_msgs else \"\"\n",
        "    ai_a = ai_msgs[-1] if ai_msgs else \"\"\n",
        "\n",
        "    return user_q, ai_a\n",
        "\n",
        "\n",
        "\n",
        "def aggregate_context(context_json):\n",
        "    if context_json is None:\n",
        "        return \"\"\n",
        "\n",
        "    texts = []\n",
        "    for item in context_json.get(\"data\", {}).get(\"vector_data\", []):\n",
        "        text = item.get(\"text\")\n",
        "        if isinstance(text, str):\n",
        "            texts.append(text)\n",
        "\n",
        "    return \" \".join(texts)\n",
        "\n",
        "\n",
        "def evaluate(chat_path, context_path):\n",
        "    chat_text = load_file_text(chat_path)\n",
        "    context_text = load_file_text(context_path)\n",
        "\n",
        "    try:\n",
        "        chat_json = json.loads(chat_text)\n",
        "        user_q, ai_a = extract_last_turns(chat_json)\n",
        "    except Exception:\n",
        "        print(\"⚠️ JSON parsing failed, using regex fallback\")\n",
        "        user_q, ai_a = extract_last_turns_fallback(chat_text)\n",
        "\n",
        "    if not user_q or not ai_a:\n",
        "        raise ValueError(\"Could not extract user/AI messages\")\n",
        "\n",
        "    tokens = estimate_tokens(ai_a)\n",
        "\n",
        "    return {\n",
        "        \"relevance_to_user\": cosine_similarity(tokenize(user_q), tokenize(ai_a)),\n",
        "        \"completeness\": completeness_score(user_q, ai_a),\n",
        "        \"hallucination_risk\": hallucination_score(ai_a, context_text),\n",
        "        \"tokens\": tokens,\n",
        "        \"estimated_cost_usd\": estimate_cost(tokens)\n",
        "    }\n"
      ]
    }
  ]
}