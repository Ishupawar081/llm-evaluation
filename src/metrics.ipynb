{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcFluEJsrkiw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"[a-zA-Z0-9']+\", text.lower())\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a, b = Counter(a), Counter(b)\n",
        "    dot = sum(a[k] * b.get(k, 0) for k in a)\n",
        "    norm_a = math.sqrt(sum(v*v for v in a.values()))\n",
        "    norm_b = math.sqrt(sum(v*v for v in b.values()))\n",
        "    return dot / (norm_a * norm_b) if norm_a and norm_b else 0.0\n",
        "\n",
        "def extract_keywords(text):\n",
        "    stopwords = {\"the\",\"is\",\"are\",\"of\",\"to\",\"for\",\"and\",\"or\",\"with\",\"my\",\"i\",\"you\"}\n",
        "    return {t for t in tokenize(text) if t not in stopwords}\n",
        "\n",
        "def completeness_score(user_text, ai_text):\n",
        "    user_keys = extract_keywords(user_text)\n",
        "    ai_tokens = set(tokenize(ai_text))\n",
        "    return len(user_keys & ai_tokens) / len(user_keys) if user_keys else 1.0\n",
        "\n",
        "def extract_entities(text):\n",
        "    return re.findall(r\"\\b[A-Z][a-zA-Z]+\\b\", text)\n",
        "\n",
        "def extract_numbers(text):\n",
        "    return re.findall(r\"\\b\\d+(?:,\\d+)*\\b\", text)\n",
        "\n",
        "def hallucination_score(answer, context):\n",
        "    ans_entities = set(extract_entities(answer))\n",
        "    ctx_entities = set(extract_entities(context))\n",
        "\n",
        "    ans_nums = set(extract_numbers(answer))\n",
        "    ctx_nums = set(extract_numbers(context))\n",
        "\n",
        "    entity_match = len(ans_entities & ctx_entities) / (len(ans_entities) or 1)\n",
        "    number_match = len(ans_nums & ctx_nums) / (len(ans_nums) or 1)\n",
        "\n",
        "    return 1 - (0.6 * entity_match + 0.4 * number_match)\n",
        "\n",
        "def estimate_tokens(text):\n",
        "    return len(tokenize(text))\n",
        "\n",
        "def estimate_cost(tokens, price_per_token=0.000002):\n",
        "    return tokens * price_per_token\n"
      ]
    }
  ]
}